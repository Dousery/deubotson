import streamlit as st
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import os
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import time

load_dotenv()

INDEX_DIRECTORY = "faiss_index"

def get_conversational_chain():
    prompt_template = """
    1. Sana kullan覺c覺n覺n sorusunu ve ilgili metin al覺nt覺lar覺n覺 salayaca覺m.
    2. G繹revin, yaln覺zca salanan metin al覺nt覺lar覺n覺 kullanarak Dokuz Eyl羹l niversitesi ad覺na cevap vermektir.
    3. Yan覺t覺 olutururken u kurallara dikkat et:
    - Salanan metin al覺nt覺s覺nda a癟覺k癟a yer alan bilgileri kullan.
    - Metin al覺nt覺s覺nda a癟覺k癟a bulunmayan cevaplar覺 tahmin etmeye veya uydurmaya 癟al覺ma.
    4. Yan覺t覺, T羹rk癟e dilinde ve anla覺l覺r bir ekilde ver.
    5. Kullan覺c覺ya her zaman yard覺mc覺 olmaya 癟al覺, ancak mevcut bilgilere dayanmayan yan覺tlardan ka癟覺n.
    6. Eer \"Sen kimsin\" diye bir soru gelirse \"Ben Dokuz Eyl羹l niversitesinin asistan botuyum, amac覺m sizlere 羹niversite hakk覺nda bilgi salamak! Size nas覺l yard覺mc覺 olabilirim?\" diye cevap ver.
    Eer haz覺rsan, sana kullan覺c覺n覺n sorusunu ve ilgili metin al覺nt覺s覺n覺 sal覺yorum.
    Context: \n {context}?\n
    Kullan覺c覺 Sorusu: \n{question}\n
    Yan覺t:
    """

    model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.3)

    prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)

    return chain

def display_text_with_effect(text):
    """
    Metni token token (kelime kelime) ekrana yazd覺rma efekti.
    """
    placeholder = st.empty()  # Dinamik g羹ncellemeler i癟in bir placeholder
    displayed_text = ""  # G繹sterilen metni oluturmak i癟in bir string
    for token in text.split():
        displayed_text += token + " "  # Token'lar覺 birletir
        placeholder.markdown(f"<div style='font-size:15px;'>{displayed_text}</div>", unsafe_allow_html=True)
        time.sleep(0.1)  # Her token aras覺nda gecikme ekle

def user_input(input):
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

    try:
        new_db = FAISS.load_local(INDEX_DIRECTORY, embeddings, allow_dangerous_deserialization=True)
        docs = new_db.similarity_search(input)
    except Exception as e:
        st.error(f"FAISS veritaban覺 y羹klenirken hata olutu: {str(e)}")
        return

    chain = get_conversational_chain()

    response = chain(
        {"input_documents": docs, "question": input}, return_only_outputs=True
    )

    # Cevab覺 yazd覺rma efektiyle ekrana g繹ster
    display_text_with_effect(response["output_text"])

def main():
    st.set_page_config(page_title="DEUbot", page_icon="", layout="centered")
    st.header("Merhaba ben DEUbot ")
    st.subheader("niversitemiz hakk覺nda ne 繹renmek istersin?")

    # Kullan覺c覺dan soru al
    user_question = st.text_input("Sorunuzu Giriniz:")
    if user_question:
        with st.spinner("Sorunuz ileniyor, l羹tfen bekleyin..."):
            user_input(user_question)

if __name__ == "__main__":
    main()